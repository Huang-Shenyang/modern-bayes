---
title: 'Homework 4'
author: "STA-360-602"
# date: "TBD"
output: pdf_document
indent: true
documentclass: article
---

Total points: 10 (reproducibility) + 10 (Q1) + 25 (Q2) = 45 points.\

1. (10 points, 5 points each) Hoff, 3.10 (Change of variables).
  
  (a) $\theta \sim \text{beta}(a,b), \psi=\log[\theta/(1-\theta)]$. Obtain the form of $p_\psi$ and plot it for the case that $a=b=1$.

  \textcolor{blue}{Q1a Ans:}
  \begin{align*}
  \psi &= \log[\theta/(1-\theta)] \\
  e^\psi &= \theta/(1-\theta) \\
  (1-\theta)e^\psi &= \theta \\
  e^\psi &= \theta + \theta e^\psi \\
  \theta &= \frac{e^\psi}{1+e^\psi} = h(\psi) \\
  \text{Note that, } 0 &< h(\psi) = \frac{e^\psi}{1+e^\psi} < 1. \\
  \text{Then, } \ & \\
  p_\psi(\psi) &= p_\theta(h(\psi)) \times \left|\dfrac{dh}{d\psi}\right| \\
  &= \text{Beta}(h(\psi)|a,b) \times \left|\dfrac{d(\frac{e^\psi}{1+e^\psi})}{d\psi}\right|\\
  &= \frac{1}{B(a,b)}h(\psi)^{a-1}(1-h(\psi))^{b-1}I(0<h(\psi)<1) \times \left| \frac{e^\psi}{1+e^\psi} - \frac{e^{2\psi}}{(1+e^\psi)^2} \right|  \\
  &= \frac{1}{B(a,b)} \frac{e^{(a-1)\psi}}{(1+e^\psi)^{(a-1)}} \frac{1}{(1+e^\psi)^{(b-1)}} \left| \frac{(1+e^\psi)e^\psi - e^{2\psi}}{(1+e^\psi)^2} \right| \\
  &= \frac{1}{B(a,b)} \frac{e^{(a-1)\psi}}{(1+e^\psi)^{(a+b-2)}} \left| \frac{e^{\psi}}{(1+e^\psi)^2} \right| \\
  &= \frac{1}{B(a,b)} \frac{e^{a\psi}}{(1+e^\psi)^{(a+b)}} \\
  \end{align*}
  
  
```{r, echo=F, include=T}
# plot for the case a=b=1
a=1
b=1
psi <- seq(-5,5,length=10000)
p_psi <- (1/beta(a,b)) * exp(a*psi) / ((1+exp(psi))^(a+b))
# make plot
plot(psi, p_psi,
     type='l', lwd=2, # line
     # ylim = c(0,0.3),
     main='Probability density of psi',
     xlab='psi',
     ylab='probability density')

```
  
  
  \newpage
  
  
  (b) $\theta \sim \text{gamma}(a,b), \psi=\log\theta$. Obtain the form of $p_\psi$ and plot it for the case that $a=b=1$.

  \textcolor{blue}{Q1b Ans:}
  \begin{align*}
  \psi &= \log\theta \\
  e^\psi &= \theta = h(\psi) \\
  \text{Note that, } h(\psi) &= e^\psi > 0. \\
  \text{Then, } \ & \\
  p_\psi(\psi) &= p_\theta(h(\psi)) \times \left|\dfrac{dh}{d\psi}\right| \\
  &= \text{Gamma}(h(\psi)|a,b) \times \left|\dfrac{d(e^\psi)}{d\psi}\right|\\
  &= \frac{b^a}{\Gamma(a)}h(\psi)^{a-1}e^{-bh(\psi)}I(h(\psi)>0) \times \left| e^\psi \right| \\
  &= \frac{b^a}{\Gamma(a)}e^{(a-1)\psi} e^{-b\exp(\psi)} e^\psi \\
  &= \frac{b^a}{\Gamma(a)}e^{a\psi - b\exp(\psi)} \\
  \end{align*}

```{r, echo=F, include=T}
# plot for the case a=b=1
a=1
b=1
psi <- seq(-5,5,length=10000)
p_psi_2 <- (b^a/gamma(a)) * exp( a*psi - b*exp(psi) )
# make plot
plot(psi, p_psi_2,
     type='l', lwd=2, # line
     # ylim = c(0,0.3),
     main='Probability density of psi',
     xlab='psi',
     ylab='probability density')

```

\newpage

2. *Lab component* (25 points total) Please refer to lab 4 and complete tasks 4---5.

```{r setup for lab tasks, include=T, warning=F, message=F}
library(ggplot2)
library(tidyverse)

set.seed(2022) # for reproducibility

# input data
# spurters
x <- c(18, 40, 15, 17, 20, 44, 38)
# controls
y <- c(-4, 0, -19, 24, 19, 10, 5, 10, 29, 13, -9, -8, 
       20, -1, 12, 21, -7, 14, 13, 20, 11, 16, 15, 27, 
       23, 36, -33, 34, 13, 11, -19, 21, 6, 25, 30, 22, 
       -28, 15, 26, -1, -2, 43, 23, 22, 25, 16, 10, 29)

# priors
m <- 0
c <- 1
a <- 1/2
b <- 10^2*a

```


(a) (10) Task 4

\textcolor{blue}{Q2a Ans:}

```{r Task 4, echo=T}
# define function to compute posteriors
computePosteriors <- function(data, m, c, a, b) {
  n <- length(data)
  M <- (c*m+sum(data)) / (c+n)
  C <- c + n
  A <- a + n/2
  B <- b + (c*m^2 - C*M^2 + sum(data^2))/2
  return(c(M, C, A, B))
}

# define function to draw samples from the NormalGamma distribution
drawNormalGamma <- function(ndraws, params) {
  m <- params[1]
  c <- params[2]
  a <- params[3]
  b <- params[4]
  # first drawing samples from the Gamma distribution
  # and then use each pair of parameters (mean and sd) 
  # to get samples from the Normal distribution 
  
  # Use a,b to get lambda (1/variance) which will be used in rnorm
  lambda <- rgamma(ndraws, a, b)
  mu <- rnorm(ndraws, m, sqrt(1/(c*lambda))) 
  # Note that the rnorm function takes the standard deviation, not the variance
  
  # output: random samples of mu and lambda
  return(data.frame(mu = mu, 
                    lambda = lambda, 
                    sd = 1/sqrt(lambda)))
  # we defined lambda = 1/variance, so compute sd from lambda
}

# draw samples of mu from the posterior distributions 
post_mu_S <- drawNormalGamma(10e6, computePosteriors(x, m, c, a, b))
post_mu_C <- drawNormalGamma(10e6, computePosteriors(y, m, c, a, b))

p <- mean(post_mu_S$mu > post_mu_C$mu)
p

```

In 97% of all random samples of the posterior mean for the IQ score change in two groups, the spurters group has greater posterior mean of the IQ score change than that of the control group. 

\newpage


(b) (15) Task 5

\textcolor{blue}{Q2b Ans:}

```{r 5 check prior assumptions, echo=T, warning=F, message=F}
# spurters
y_prior <- drawNormalGamma(5*10e2, c(m,c,a,b))

ggplot(y_prior) +
  geom_point(aes(x=mu, y=sd), 
             size=1, color='darkgreen', alpha=0.5) +
  scale_x_continuous(limits=c(-50,50),
                     name='mu, mean change in IQ score') + 
  scale_y_continuous(limits=c(0,40),
                     name='lambda^(1/2), std. dev. of change in IQ score') +
  ggtitle(label='Samples of (mu, sigma) from the prior distribution') +
  theme_light() + 
  NULL

```

- $\mu$ correctly centers around 0 as assumed in the prior, but it is quite different from the posterior mean for either group since we set $c=1$ which has a low weight on the priors and make them uninformative. 
- Precision $\lambda$ is also allowed to vary and it becomes lower (shown as larger standard deviation on the plot) as $\mu$ gets larger, which behaves in accordance with our choice of the NormalGamma distribution (that we are not sure how variable people's IQ score changes would be). 



